{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Performance benchmark for Fast Depth Pipeline\n",
    "Tests different configurations to find optimal settings\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from fast_depth_pipeline import FastDepthPipeline\n",
    "\n",
    "def create_test_image(size=(512, 512)):\n",
    "    \"\"\"Create a test image for benchmarking\"\"\"\n",
    "    # Create a simple test pattern\n",
    "    img = np.random.randint(0, 255, (*size, 3), dtype=np.uint8)\n",
    "    # Add some structure (circles, lines)\n",
    "    center = (size[0]//2, size[1]//2)\n",
    "    y, x = np.ogrid[:size[0], :size[1]]\n",
    "    mask = (x - center[0])**2 + (y - center[1])**2 < (size[0]//4)**2\n",
    "    img[mask] = [255, 0, 0]  # Red circle\n",
    "    \n",
    "    return img\n",
    "\n",
    "def benchmark_configuration(config_name, **kwargs):\n",
    "    \"\"\"Benchmark a specific configuration\"\"\"\n",
    "    print(f\"\\nüß™ Testing {config_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize pipeline\n",
    "        pipeline = FastDepthPipeline(**kwargs)\n",
    "        \n",
    "        # Create test image\n",
    "        test_img = create_test_image()\n",
    "        test_path = Path(\"test_image.jpg\")\n",
    "        \n",
    "        # Save test image\n",
    "        from PIL import Image\n",
    "        Image.fromarray(test_img).save(test_path)\n",
    "        \n",
    "        # Warmup run\n",
    "        pipeline.process_image(test_path, skip_visual=True)\n",
    "        \n",
    "        # Benchmark runs\n",
    "        times = []\n",
    "        for i in range(5):\n",
    "            start = time.time()\n",
    "            result = pipeline.process_image(test_path, skip_visual=True)\n",
    "            end = time.time()\n",
    "            times.append(end - start)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è  Average time: {avg_time:.3f}s (¬±{std_time:.3f}s)\")\n",
    "        print(f\"   üìä Points generated: {result['meta']['num_points']}\")\n",
    "        print(f\"   üéØ Shape detected: {result['analysis']['type']}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        test_path.unlink()\n",
    "        \n",
    "        return avg_time, result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run comprehensive benchmarks\"\"\"\n",
    "    print(\"üèÉ‚Äç‚ôÇÔ∏è Fast Depth Pipeline Benchmark\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check Metal availability\n",
    "    metal_available = torch.backends.mps.is_available()\n",
    "    print(f\"üîã Metal backend available: {metal_available}\")\n",
    "    \n",
    "    # Test configurations\n",
    "    configs = [\n",
    "        (\"Ultra Fast (256px, sparse)\", {\n",
    "            \"model_type\": \"midas_small\",\n",
    "            \"input_size\": 256,\n",
    "            \"use_metal\": metal_available\n",
    "        }),\n",
    "        (\"Fast (384px, sparse)\", {\n",
    "            \"model_type\": \"midas_small\", \n",
    "            \"input_size\": 384,\n",
    "            \"use_metal\": metal_available\n",
    "        }),\n",
    "        (\"Balanced (512px, sparse)\", {\n",
    "            \"model_type\": \"midas_small\",\n",
    "            \"input_size\": 512,\n",
    "            \"use_metal\": metal_available\n",
    "        }),\n",
    "        (\"CPU Only (256px)\", {\n",
    "            \"model_type\": \"midas_small\",\n",
    "            \"input_size\": 256,\n",
    "            \"use_metal\": False\n",
    "        })\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for config_name, config_params in configs:\n",
    "        avg_time, result = benchmark_configuration(config_name, **config_params)\n",
    "        if avg_time is not None:\n",
    "            results[config_name] = avg_time\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nüìä BENCHMARK RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if results:\n",
    "        fastest_config = min(results, key=results.get)\n",
    "        \n",
    "        for config_name, avg_time in sorted(results.items(), key=lambda x: x[1]):\n",
    "            speedup = results[fastest_config] / avg_time if avg_time > 0 else 1\n",
    "            print(f\"   {config_name}: {avg_time:.3f}s ({speedup:.1f}x)\")\n",
    "        \n",
    "        print(f\"\\nüèÜ Fastest configuration: {fastest_config}\")\n",
    "        print(f\"üéØ Recommended for M2 Mac: Ultra Fast (256px, sparse)\")\n",
    "        \n",
    "        # Performance tips\n",
    "        print(\"\\nüí° Performance Tips:\")\n",
    "        print(\"   ‚Ä¢ Use --size 256 for fastest processing\")\n",
    "        print(\"   ‚Ä¢ Use --sample-rate 8 for sparse point clouds\")\n",
    "        print(\"   ‚Ä¢ Use --skip-visual to avoid 3D rendering\")\n",
    "        print(\"   ‚Ä¢ Process images in batches for better efficiency\")\n",
    "        \n",
    "        if metal_available:\n",
    "            print(\"   ‚Ä¢ Metal backend is enabled for GPU acceleration\")\n",
    "        else:\n",
    "            print(\"   ‚Ä¢ Consider enabling Metal backend for better performance\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No successful benchmark runs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp-viz1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
