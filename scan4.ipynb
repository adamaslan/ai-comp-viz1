{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30081221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîã Metal backend available: True\n",
      "üêç PyTorch version: 2.7.1\n",
      "üéØ Setup complete! Ready to use in Jupyter.\n",
      "üìù Run 'quick_test()' to test the pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Fast Depth Pipeline - Jupyter Notebook Setup\n",
    "# Run these cells in order in your Jupyter notebook\n",
    "\n",
    "# Cell 1: Install packages (run once)\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages in Jupyter\"\"\"\n",
    "    packages = [\n",
    "        'torch', 'torchvision', 'torchaudio',  # PyTorch with Metal support\n",
    "        'opencv-python', 'pillow', 'numpy',    # Image processing\n",
    "        'open3d', 'timm', 'matplotlib'         # 3D processing and MiDaS deps\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "            print(f\"‚úÖ {package} installed successfully\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"‚ùå Failed to install {package}\")\n",
    "\n",
    "# Uncomment and run this line once:\n",
    "# install_packages()\n",
    "\n",
    "# Cell 2: Optional ZoeDepth installation (run once if needed)\n",
    "# !pip install git+https://github.com/isl-org/ZoeDepth.git\n",
    "\n",
    "# Cell 3: Test Metal backend\n",
    "import torch\n",
    "print(f\"üîã Metal backend available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"üêç PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Cell 4: Fast Depth Pipeline Implementation\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class FastDepthPipeline:\n",
    "    def __init__(self, model_type='midas_small', input_size=256, use_metal=True):\n",
    "        \"\"\"\n",
    "        Initialize the fast depth estimation pipeline\n",
    "        \n",
    "        Args:\n",
    "            model_type: 'midas_small' or 'zoe_nano'\n",
    "            input_size: Input image size (256, 384, or 512)\n",
    "            use_metal: Use Apple Metal backend for acceleration\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.input_size = input_size\n",
    "        self.device = self._setup_device(use_metal)\n",
    "        self.model = self._load_model()\n",
    "        \n",
    "        print(f\"üöÄ Pipeline initialized:\")\n",
    "        print(f\"   Model: {model_type}\")\n",
    "        print(f\"   Input size: {input_size}x{input_size}\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "    \n",
    "    def _setup_device(self, use_metal):\n",
    "        \"\"\"Setup optimal device for M2 Mac\"\"\"\n",
    "        if use_metal and torch.backends.mps.is_available():\n",
    "            return torch.device('mps')\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device('cuda')\n",
    "        else:\n",
    "            return torch.device('cpu')\n",
    "    \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load lightweight depth estimation model\"\"\"\n",
    "        if self.model_type == 'midas_small':\n",
    "            # Use MiDaS Small (DPT-Hybrid)\n",
    "            model = torch.hub.load('intel-isl/MiDaS', 'DPT_Hybrid', pretrained=True)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            return model\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Fast image preprocessing with resizing\"\"\"\n",
    "        # Load image\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize for speed\n",
    "        h, w = img.shape[:2]\n",
    "        scale = self.input_size / max(h, w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Pad to square\n",
    "        pad_h = self.input_size - new_h\n",
    "        pad_w = self.input_size - new_w\n",
    "        img = np.pad(img, ((0, pad_h), (0, pad_w), (0, 0)), mode='constant')\n",
    "        \n",
    "        # Convert to tensor\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        return img.to(self.device), (h, w), scale\n",
    "    \n",
    "    def estimate_depth(self, image_tensor):\n",
    "        \"\"\"Fast depth estimation\"\"\"\n",
    "        with torch.no_grad():\n",
    "            depth = self.model(image_tensor)\n",
    "            depth = depth.squeeze().cpu().numpy()\n",
    "            depth = (depth - depth.min()) / (depth.max() - depth.min())\n",
    "        return depth\n",
    "    \n",
    "    def create_sparse_point_cloud(self, depth_map, rgb_image, sample_rate=4):\n",
    "        \"\"\"Create sparse point cloud for faster processing\"\"\"\n",
    "        h, w = depth_map.shape\n",
    "        \n",
    "        # Sample every Nth pixel for speed\n",
    "        y_coords, x_coords = np.meshgrid(\n",
    "            np.arange(0, h, sample_rate),\n",
    "            np.arange(0, w, sample_rate),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        \n",
    "        # Get depth and color values\n",
    "        depths = depth_map[y_coords, x_coords]\n",
    "        colors = rgb_image[y_coords, x_coords]\n",
    "        \n",
    "        # Create 3D coordinates\n",
    "        focal_length = max(h, w)\n",
    "        cx, cy = w // 2, h // 2\n",
    "        \n",
    "        z = depths * 10\n",
    "        x = (x_coords - cx) * z / focal_length\n",
    "        y = (y_coords - cy) * z / focal_length\n",
    "        \n",
    "        points = np.stack([x.flatten(), y.flatten(), z.flatten()], axis=1)\n",
    "        colors = colors.reshape(-1, 3) / 255.0\n",
    "        \n",
    "        # Remove invalid points\n",
    "        valid_mask = ~np.isnan(points).any(axis=1)\n",
    "        points = points[valid_mask]\n",
    "        colors = colors[valid_mask]\n",
    "        \n",
    "        return points, colors\n",
    "    \n",
    "    def analyze_3d_shape(self, points, colors):\n",
    "        \"\"\"Fast 3D shape analysis\"\"\"\n",
    "        if len(points) < 10:\n",
    "            return {\"type\": \"unknown\", \"confidence\": 0.0}\n",
    "        \n",
    "        # Calculate basic statistics\n",
    "        bbox_min = np.min(points, axis=0)\n",
    "        bbox_max = np.max(points, axis=0)\n",
    "        bbox_size = bbox_max - bbox_min\n",
    "        \n",
    "        z_values = points[:, 2]\n",
    "        z_std = np.std(z_values)\n",
    "        \n",
    "        aspect_ratio_xy = bbox_size[0] / bbox_size[1] if bbox_size[1] > 0 else 1.0\n",
    "        aspect_ratio_z = bbox_size[2] / max(bbox_size[0], bbox_size[1]) if max(bbox_size[0], bbox_size[1]) > 0 else 1.0\n",
    "        \n",
    "        # Simple classification\n",
    "        if z_std < 0.5 and aspect_ratio_z < 0.1:\n",
    "            return {\"type\": \"flat_surface\", \"confidence\": 0.8}\n",
    "        elif aspect_ratio_xy > 3.0 or aspect_ratio_xy < 0.3:\n",
    "            return {\"type\": \"elongated_object\", \"confidence\": 0.7}\n",
    "        elif z_std > 1.0:\n",
    "            return {\"type\": \"3d_object\", \"confidence\": 0.6}\n",
    "        else:\n",
    "            return {\"type\": \"unknown\", \"confidence\": 0.3}\n",
    "    \n",
    "    def process_image(self, image_path, sample_rate=4, show_results=True):\n",
    "        \"\"\"Process image and optionally display results\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Process pipeline\n",
    "        image_tensor, original_size, scale = self.preprocess_image(image_path)\n",
    "        depth_map = self.estimate_depth(image_tensor)\n",
    "        \n",
    "        # Create point cloud\n",
    "        rgb_image = cv2.imread(str(image_path))\n",
    "        rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "        rgb_image = cv2.resize(rgb_image, (self.input_size, self.input_size))\n",
    "        \n",
    "        points, colors = self.create_sparse_point_cloud(depth_map, rgb_image, sample_rate)\n",
    "        analysis = self.analyze_3d_shape(points, colors)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Display results in notebook\n",
    "        if show_results:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            # Original image\n",
    "            orig_img = cv2.imread(str(image_path))\n",
    "            orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n",
    "            axes[0].imshow(orig_img)\n",
    "            axes[0].set_title('Original Image')\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # Depth map\n",
    "            axes[1].imshow(depth_map, cmap='plasma')\n",
    "            axes[1].set_title('Depth Map')\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            # Point cloud projection\n",
    "            if len(points) > 0:\n",
    "                axes[2].scatter(points[:, 0], points[:, 1], c=points[:, 2], cmap='viridis', s=1)\n",
    "                axes[2].set_title('Point Cloud (Top View)')\n",
    "                axes[2].set_aspect('equal')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print analysis\n",
    "            print(f\"üìä Analysis Results:\")\n",
    "            print(f\"   Shape: {analysis['type']}\")\n",
    "            print(f\"   Confidence: {analysis['confidence']:.2f}\")\n",
    "            print(f\"   Processing time: {total_time:.2f}s\")\n",
    "            print(f\"   Points generated: {len(points)}\")\n",
    "        \n",
    "        return {\n",
    "            'analysis': analysis,\n",
    "            'points': points,\n",
    "            'colors': colors,\n",
    "            'depth_map': depth_map,\n",
    "            'processing_time': total_time\n",
    "        }\n",
    "\n",
    "# Cell 5: Quick test function\n",
    "def quick_test():\n",
    "    \"\"\"Quick test with a sample image\"\"\"\n",
    "    # Create a test image\n",
    "    test_img = np.random.randint(0, 255, (400, 400, 3), dtype=np.uint8)\n",
    "    # Add some structure\n",
    "    cv2.circle(test_img, (200, 200), 80, (255, 0, 0), -1)\n",
    "    cv2.rectangle(test_img, (50, 50), (150, 150), (0, 255, 0), -1)\n",
    "    \n",
    "    # Save test image\n",
    "    test_path = \"test_image.jpg\"\n",
    "    cv2.imwrite(test_path, test_img)\n",
    "    \n",
    "    # Run pipeline\n",
    "    pipeline = FastDepthPipeline(input_size=256)\n",
    "    result = pipeline.process_image(test_path, sample_rate=8)\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(test_path)\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"üéØ Setup complete! Ready to use in Jupyter.\")\n",
    "print(\"üìù Run 'quick_test()' to test the pipeline.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp-viz1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
